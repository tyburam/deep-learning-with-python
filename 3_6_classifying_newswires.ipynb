{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_6_classifying_newswires.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XJUy2gfBPwo",
        "colab_type": "text"
      },
      "source": [
        "# Doing the stuff the way it goes in the book"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnHYrtM-BYVd",
        "colab_type": "text"
      },
      "source": [
        "Importing all the stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uv1WH-4UBL_P",
        "colab_type": "code",
        "outputId": "1e0d2661-53da-43f5-936c-705823a9bfb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras\n",
        "from keras.datasets import reuters\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras import models\n",
        "from keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import copy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yOgIaVtBzPT",
        "colab_type": "text"
      },
      "source": [
        "Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQOq5HOEB0y8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K53_5evYCvw3",
        "colab_type": "text"
      },
      "source": [
        "Looking at the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nLB8UnuYYa9",
        "colab_type": "code",
        "outputId": "422a59f1-f598-4877-b7c5-d5894063e237",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8982"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HwVXY4cYZyV",
        "colab_type": "code",
        "outputId": "4471dddc-0110-4e26-d355-18ccd0f99e6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(test_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2246"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmuko6NoCwWL",
        "colab_type": "code",
        "outputId": "e04a8558-60a8-4eb5-dc61-349a27de8263",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "train_data[10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 245,\n",
              " 273,\n",
              " 207,\n",
              " 156,\n",
              " 53,\n",
              " 74,\n",
              " 160,\n",
              " 26,\n",
              " 14,\n",
              " 46,\n",
              " 296,\n",
              " 26,\n",
              " 39,\n",
              " 74,\n",
              " 2979,\n",
              " 3554,\n",
              " 14,\n",
              " 46,\n",
              " 4689,\n",
              " 4329,\n",
              " 86,\n",
              " 61,\n",
              " 3499,\n",
              " 4795,\n",
              " 14,\n",
              " 61,\n",
              " 451,\n",
              " 4329,\n",
              " 17,\n",
              " 12]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcwpqY3DC3HF",
        "colab_type": "code",
        "outputId": "b4f24ba5-3228-4833-acc2-5b94e4a4b49b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_labels[10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nER4kAgC6xm",
        "colab_type": "code",
        "outputId": "c368fb55-bbb0-4b5d-f032-05bafae0fb04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max([max(sequence) for sequence in train_data])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OjujXTBC7hi",
        "colab_type": "text"
      },
      "source": [
        "Decoding the data to see actual text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4j5QUjSKDAD0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# word_index is a dictionary mapping words to an integer index\n",
        "word_index = reuters.get_word_index()\n",
        "# We reverse it, mapping integer indices to words\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "# We decode the review; note that our indices were offset by 3\n",
        "# because 0, 1 and 2 are reserved indices for \"padding\", \"start of sequence\", and \"unknown\".\n",
        "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[10]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eBYiW0CDCBT",
        "colab_type": "code",
        "outputId": "64d821e7-b6bd-4d87-b04a-2636d822b4e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "decoded_review"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'? period ended december 31 shr profit 11 cts vs loss 24 cts net profit 224 271 vs loss 511 349 revs 7 258 688 vs 7 200 349 reuter 3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aud-kVXJDHWt",
        "colab_type": "text"
      },
      "source": [
        "Preparing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucf48gErDJ5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    # Create an all-zero matrix of shape (len(sequences), dimension)\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.  # set specific indices of results[i] to 1s\n",
        "    return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yI8mYSrUZDME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_one_hot(labels, dimension=46):\n",
        "    results = np.zeros((len(labels), dimension))\n",
        "    for i, label in enumerate(labels):\n",
        "        results[i, label] = 1.\n",
        "    return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfzfXjg4DMPh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Our vectorized training data\n",
        "x_train = vectorize_sequences(train_data)\n",
        "# Our vectorized test data\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFw3f1UrZRvb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Our vectorized training labels\n",
        "one_hot_train_labels = to_one_hot(train_labels)\n",
        "# Our vectorized test labels\n",
        "one_hot_test_labels = to_one_hot(test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqHNA-QTZRiL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "one_hot_train_labels = to_categorical(train_labels)\n",
        "one_hot_test_labels = to_categorical(test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAkxI5eEDUWI",
        "colab_type": "text"
      },
      "source": [
        "Building network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZcnz5aWDV7H",
        "colab_type": "code",
        "outputId": "f9b82f7e-a9ce-464d-b61c-d9445fc4fcf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VotuxO9lDZ-N",
        "colab_type": "text"
      },
      "source": [
        "Preparing network to be used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDrwBMTNDb5y",
        "colab_type": "code",
        "outputId": "4e65a70b-f330-4ece-fd78-5d9782294253",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epCM0y9CD24j",
        "colab_type": "text"
      },
      "source": [
        "Preparing validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96gpQCpVD4dj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_val = x_train[:1000]\n",
        "partial_x_train = x_train[1000:]\n",
        "\n",
        "y_val = one_hot_train_labels[:1000]\n",
        "partial_y_train = one_hot_train_labels[1000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENH7tM-3Dzhv",
        "colab_type": "text"
      },
      "source": [
        "Performing training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcqpJzQtD0I5",
        "colab_type": "code",
        "outputId": "d0fc3b18-4c42-423c-ac56-7516eebbff57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 7982 samples, validate on 1000 samples\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "7982/7982 [==============================] - 1s 183us/step - loss: 3.2844 - acc: 0.4975 - val_loss: 2.7879 - val_acc: 0.5360\n",
            "Epoch 2/20\n",
            "7982/7982 [==============================] - 1s 134us/step - loss: 2.3851 - acc: 0.4241 - val_loss: 2.0732 - val_acc: 0.3540\n",
            "Epoch 3/20\n",
            "7982/7982 [==============================] - 1s 158us/step - loss: 1.7998 - acc: 0.3514 - val_loss: 1.7077 - val_acc: 0.3540\n",
            "Epoch 4/20\n",
            "7982/7982 [==============================] - 1s 145us/step - loss: 1.3941 - acc: 0.3514 - val_loss: 1.4513 - val_acc: 0.3540\n",
            "Epoch 5/20\n",
            "7982/7982 [==============================] - 1s 136us/step - loss: 1.1507 - acc: 0.3867 - val_loss: 1.2101 - val_acc: 0.6710\n",
            "Epoch 6/20\n",
            "7982/7982 [==============================] - 1s 133us/step - loss: 0.7177 - acc: 0.8399 - val_loss: 0.9459 - val_acc: 0.8060\n",
            "Epoch 7/20\n",
            "7982/7982 [==============================] - 1s 137us/step - loss: 0.5217 - acc: 0.8943 - val_loss: 0.9390 - val_acc: 0.7970\n",
            "Epoch 8/20\n",
            "7982/7982 [==============================] - 1s 133us/step - loss: nan - acc: 0.7611 - val_loss: nan - val_acc: 0.0060\n",
            "Epoch 9/20\n",
            "7982/7982 [==============================] - 1s 134us/step - loss: nan - acc: 0.0061 - val_loss: nan - val_acc: 0.0060\n",
            "Epoch 10/20\n",
            "7982/7982 [==============================] - 1s 132us/step - loss: nan - acc: 0.0061 - val_loss: nan - val_acc: 0.0060\n",
            "Epoch 11/20\n",
            "7982/7982 [==============================] - 1s 135us/step - loss: nan - acc: 0.0061 - val_loss: nan - val_acc: 0.0060\n",
            "Epoch 12/20\n",
            "7982/7982 [==============================] - 1s 135us/step - loss: nan - acc: 0.0061 - val_loss: nan - val_acc: 0.0060\n",
            "Epoch 13/20\n",
            "7982/7982 [==============================] - 1s 135us/step - loss: nan - acc: 0.0061 - val_loss: nan - val_acc: 0.0060\n",
            "Epoch 14/20\n",
            "7982/7982 [==============================] - 1s 133us/step - loss: nan - acc: 0.0061 - val_loss: nan - val_acc: 0.0060\n",
            "Epoch 15/20\n",
            "7982/7982 [==============================] - 1s 135us/step - loss: nan - acc: 0.0061 - val_loss: nan - val_acc: 0.0060\n",
            "Epoch 16/20\n",
            "7982/7982 [==============================] - 1s 134us/step - loss: nan - acc: 0.0061 - val_loss: nan - val_acc: 0.0060\n",
            "Epoch 17/20\n",
            "7982/7982 [==============================] - 1s 138us/step - loss: nan - acc: 0.0061 - val_loss: nan - val_acc: 0.0060\n",
            "Epoch 18/20\n",
            "7982/7982 [==============================] - 1s 135us/step - loss: nan - acc: 0.0061 - val_loss: nan - val_acc: 0.0060\n",
            "Epoch 19/20\n",
            "7982/7982 [==============================] - 1s 135us/step - loss: nan - acc: 0.0061 - val_loss: nan - val_acc: 0.0060\n",
            "Epoch 20/20\n",
            "7982/7982 [==============================] - 1s 134us/step - loss: nan - acc: 0.0061 - val_loss: nan - val_acc: 0.0060\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-MQge5JD-I9",
        "colab_type": "text"
      },
      "source": [
        "Looking at the training performance history"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ver5PZwEBDC",
        "colab_type": "code",
        "outputId": "27f09854-c7f5-406c-abb5-f56327ddaa0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "history_dict = history.history\n",
        "history_dict.keys()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b729n5eGEGlS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLJuF7stEEiv",
        "colab_type": "code",
        "outputId": "371db28c-8837-4cdd-999a-a0f8c5dfcda1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# \"bo\" is for \"blue dot\"\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "# b is for \"solid blue line\"\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQ0En9JMETqp",
        "colab_type": "code",
        "outputId": "9a43ee6a-dc27-4857-e29a-c0850a3317cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "plt.clf()   # clear figure\n",
        "acc_values = history_dict['acc']\n",
        "val_acc_values = history_dict['val_acc']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytqdq45pERYw",
        "colab_type": "code",
        "outputId": "d667d620-a710-407d-cfa1-b39aa497a23f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niEiSkoKIiCQpKYiISNL/B4eFvLKQHdibAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7BIISVCEexx",
        "colab_type": "text"
      },
      "source": [
        "New model and it's evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCFsI0lNEiCh",
        "colab_type": "code",
        "outputId": "79f95e0e-0791-4e1a-cdb4-0469f4f20d2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(partial_x_train,\n",
        "          partial_y_train,\n",
        "          epochs=8,\n",
        "          batch_size=512,\n",
        "          validation_data=(x_val, y_val))\n",
        "\n",
        "results = model.evaluate(x_test, one_hot_test_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7982 samples, validate on 1000 samples\n",
            "Epoch 1/8\n",
            "7982/7982 [==============================] - 1s 184us/step - loss: 2.5416 - acc: 0.5371 - val_loss: 1.7163 - val_acc: 0.6290\n",
            "Epoch 2/8\n",
            "7982/7982 [==============================] - 1s 139us/step - loss: 1.4006 - acc: 0.7070 - val_loss: 1.3295 - val_acc: 0.6980\n",
            "Epoch 3/8\n",
            "7982/7982 [==============================] - 1s 137us/step - loss: 1.0514 - acc: 0.7694 - val_loss: 1.1884 - val_acc: 0.7470\n",
            "Epoch 4/8\n",
            "7982/7982 [==============================] - 1s 134us/step - loss: 0.8222 - acc: 0.8276 - val_loss: 1.0694 - val_acc: 0.7780\n",
            "Epoch 5/8\n",
            "7982/7982 [==============================] - 1s 138us/step - loss: 0.6547 - acc: 0.8637 - val_loss: 1.0651 - val_acc: 0.7650\n",
            "Epoch 6/8\n",
            "7982/7982 [==============================] - 1s 135us/step - loss: 0.5216 - acc: 0.8896 - val_loss: 0.9520 - val_acc: 0.8090\n",
            "Epoch 7/8\n",
            "7982/7982 [==============================] - 1s 138us/step - loss: 0.4158 - acc: 0.9138 - val_loss: 0.9662 - val_acc: 0.8020\n",
            "Epoch 8/8\n",
            "7982/7982 [==============================] - 1s 135us/step - loss: 0.3385 - acc: 0.9281 - val_loss: 0.9253 - val_acc: 0.8100\n",
            "2246/2246 [==============================] - 0s 101us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4x0dn7VkEkW5",
        "colab_type": "code",
        "outputId": "f8e21118-1491-42fe-bd96-c6e6612bda1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "results"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9926834533178477, 0.7822796082188801]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rBynpgiamtO",
        "colab_type": "text"
      },
      "source": [
        "Comparing to random baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeKCaX1Caory",
        "colab_type": "code",
        "outputId": "fa8c74ae-374f-48f4-cb6b-b6c74043ae51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_labels_copy = copy.copy(test_labels)\n",
        "np.random.shuffle(test_labels_copy)\n",
        "float(np.sum(np.array(test_labels) == np.array(test_labels_copy))) / len(test_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.19456812110418523"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUFa5CydEk7I",
        "colab_type": "text"
      },
      "source": [
        "Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hj4IM-s7EmNK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VE-IBaBca7co",
        "colab_type": "code",
        "outputId": "856b850c-046f-4248-ebf3-130fdf91cf93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predictions[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wimYl9HAa-Ag",
        "colab_type": "code",
        "outputId": "47582ae4-f19a-4a40-a4f4-e16170f9c1ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.sum(predictions[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9999998"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvcUJcDIbBzZ",
        "colab_type": "code",
        "outputId": "11c4832a-e79b-4e8f-b996-369ba1c8e5fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.argmax(predictions[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52GFdVYIbOk0",
        "colab_type": "text"
      },
      "source": [
        "### A different way to handle the labels and the loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByXaZSYWbQlC",
        "colab_type": "text"
      },
      "source": [
        "Labels as integer tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNc_ofGkbnDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = np.array(train_labels)\n",
        "y_test = np.array(test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvZaAeqSejas",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_val = x_train[:1000]\n",
        "partial_x_train = x_train[1000:]\n",
        "\n",
        "y_val = y_train[:1000]\n",
        "partial_y_train = y_train[1000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20ZXttIsf0ku",
        "colab_type": "code",
        "outputId": "40ee9549-396d-41ad-a585-ef1afda0796c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "partial_x_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7982, 10000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMfuz4b1iAWX",
        "colab_type": "code",
        "outputId": "2699be54-8d47-467e-9e6e-3998db6af79a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_val.max()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLKeASW8bpr0",
        "colab_type": "text"
      },
      "source": [
        "Changing loss to work with integer labels instead of categorical labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrDyokVSbyF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Czw15NKOb1i_",
        "colab_type": "text"
      },
      "source": [
        "New model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpEtoWhKb2rt",
        "colab_type": "code",
        "outputId": "64ec2c5e-361c-4d66-dc0d-f1fa23287fa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(4, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))\n",
        "\n",
        "# model.summary()\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(partial_x_train,\n",
        "          partial_y_train,\n",
        "          epochs=20,\n",
        "          batch_size=128,\n",
        "          validation_data=(x_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7982 samples, validate on 1000 samples\n",
            "Epoch 1/20\n",
            "7982/7982 [==============================] - 2s 269us/step - loss: 2.9107 - acc: 0.2625 - val_loss: 2.1015 - val_acc: 0.5460\n",
            "Epoch 2/20\n",
            "7982/7982 [==============================] - 2s 218us/step - loss: 1.7806 - acc: 0.5578 - val_loss: 1.6589 - val_acc: 0.5660\n",
            "Epoch 3/20\n",
            "7982/7982 [==============================] - 1s 187us/step - loss: 1.4559 - acc: 0.5946 - val_loss: 1.4956 - val_acc: 0.6120\n",
            "Epoch 4/20\n",
            "7982/7982 [==============================] - 1s 188us/step - loss: 1.2576 - acc: 0.6555 - val_loss: 1.4069 - val_acc: 0.6560\n",
            "Epoch 5/20\n",
            "7982/7982 [==============================] - 1s 183us/step - loss: 1.1084 - acc: 0.7022 - val_loss: 1.3704 - val_acc: 0.6660\n",
            "Epoch 6/20\n",
            "7982/7982 [==============================] - 1s 181us/step - loss: 0.9898 - acc: 0.7305 - val_loss: 1.3226 - val_acc: 0.6780\n",
            "Epoch 7/20\n",
            "7982/7982 [==============================] - 1s 185us/step - loss: 0.8889 - acc: 0.7672 - val_loss: 1.3137 - val_acc: 0.6940\n",
            "Epoch 8/20\n",
            "7982/7982 [==============================] - 1s 183us/step - loss: 0.8015 - acc: 0.7849 - val_loss: 1.3102 - val_acc: 0.7000\n",
            "Epoch 9/20\n",
            "7982/7982 [==============================] - 1s 186us/step - loss: 0.7290 - acc: 0.8017 - val_loss: 1.3539 - val_acc: 0.7010\n",
            "Epoch 10/20\n",
            "7982/7982 [==============================] - 2s 188us/step - loss: 0.6693 - acc: 0.8231 - val_loss: 1.3888 - val_acc: 0.7080\n",
            "Epoch 11/20\n",
            "7982/7982 [==============================] - 1s 187us/step - loss: 0.6198 - acc: 0.8393 - val_loss: 1.3992 - val_acc: 0.7120\n",
            "Epoch 12/20\n",
            "7982/7982 [==============================] - 1s 181us/step - loss: 0.5732 - acc: 0.8553 - val_loss: 1.4473 - val_acc: 0.7150\n",
            "Epoch 13/20\n",
            "7982/7982 [==============================] - 1s 183us/step - loss: 0.5378 - acc: 0.8633 - val_loss: 1.4846 - val_acc: 0.7140\n",
            "Epoch 14/20\n",
            "7982/7982 [==============================] - 1s 180us/step - loss: 0.5039 - acc: 0.8720 - val_loss: 1.5308 - val_acc: 0.7180\n",
            "Epoch 15/20\n",
            "7982/7982 [==============================] - 1s 184us/step - loss: 0.4748 - acc: 0.8787 - val_loss: 1.5496 - val_acc: 0.7180\n",
            "Epoch 16/20\n",
            "7982/7982 [==============================] - 1s 183us/step - loss: 0.4519 - acc: 0.8806 - val_loss: 1.5889 - val_acc: 0.7150\n",
            "Epoch 17/20\n",
            "7982/7982 [==============================] - 1s 184us/step - loss: 0.4282 - acc: 0.8840 - val_loss: 1.5920 - val_acc: 0.7170\n",
            "Epoch 18/20\n",
            "7982/7982 [==============================] - 1s 187us/step - loss: 0.4075 - acc: 0.8886 - val_loss: 1.6866 - val_acc: 0.7080\n",
            "Epoch 19/20\n",
            "7982/7982 [==============================] - 1s 183us/step - loss: 0.3898 - acc: 0.8911 - val_loss: 1.7089 - val_acc: 0.7110\n",
            "Epoch 20/20\n",
            "7982/7982 [==============================] - 1s 183us/step - loss: 0.3733 - acc: 0.8979 - val_loss: 1.7824 - val_acc: 0.7010\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f22acaa9a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Co3SzDcYcLhA",
        "colab_type": "text"
      },
      "source": [
        "### Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0-s1zvBcXcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def experiment(units=64, hidden=1):\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Dense(units, activation='relu', input_shape=(10000,)))\n",
        "  if hidden > 1:\n",
        "    model.add(layers.Dense(4, activation='relu'))\n",
        "    for _ in range(hidden-2):\n",
        "      model.add(layers.Dense(16, activation='relu'))\n",
        "  model.add(layers.Dense(46, activation='softmax'))\n",
        "\n",
        "  model.compile(optimizer='rmsprop',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  model.fit(partial_x_train,\n",
        "            partial_y_train,\n",
        "            epochs=20,\n",
        "            batch_size=128,\n",
        "            validation_data=(x_val, y_val))\n",
        "  \n",
        "  return model.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1eG45oXcNvt",
        "colab_type": "text"
      },
      "source": [
        "Try using larger or smaller layers: 32 units, 128 units..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogj1EL5gcQkW",
        "colab_type": "code",
        "outputId": "25dcabdb-e384-425c-fa96-6edbf8f492d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "experiment(32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7982 samples, validate on 1000 samples\n",
            "Epoch 1/20\n",
            "7982/7982 [==============================] - 1s 175us/step - loss: 2.2802 - acc: 0.5916 - val_loss: 1.5030 - val_acc: 0.6760\n",
            "Epoch 2/20\n",
            "7982/7982 [==============================] - 1s 142us/step - loss: 1.2115 - acc: 0.7471 - val_loss: 1.1494 - val_acc: 0.7600\n",
            "Epoch 3/20\n",
            "7982/7982 [==============================] - 1s 143us/step - loss: 0.8969 - acc: 0.8152 - val_loss: 1.0115 - val_acc: 0.7950\n",
            "Epoch 4/20\n",
            "7982/7982 [==============================] - 1s 143us/step - loss: 0.6995 - acc: 0.8573 - val_loss: 0.9228 - val_acc: 0.8170\n",
            "Epoch 5/20\n",
            "7982/7982 [==============================] - 1s 145us/step - loss: 0.5538 - acc: 0.8865 - val_loss: 0.8810 - val_acc: 0.8180\n",
            "Epoch 6/20\n",
            "7982/7982 [==============================] - 1s 142us/step - loss: 0.4460 - acc: 0.9082 - val_loss: 0.8460 - val_acc: 0.8230\n",
            "Epoch 7/20\n",
            "7982/7982 [==============================] - 1s 166us/step - loss: 0.3640 - acc: 0.9246 - val_loss: 0.8417 - val_acc: 0.8230\n",
            "Epoch 8/20\n",
            "7982/7982 [==============================] - 1s 151us/step - loss: 0.2997 - acc: 0.9369 - val_loss: 0.8352 - val_acc: 0.8230\n",
            "Epoch 9/20\n",
            "7982/7982 [==============================] - 1s 145us/step - loss: 0.2538 - acc: 0.9437 - val_loss: 0.8383 - val_acc: 0.8360\n",
            "Epoch 10/20\n",
            "7982/7982 [==============================] - 1s 144us/step - loss: 0.2179 - acc: 0.9470 - val_loss: 0.8706 - val_acc: 0.8250\n",
            "Epoch 11/20\n",
            "7982/7982 [==============================] - 1s 143us/step - loss: 0.1910 - acc: 0.9516 - val_loss: 0.8564 - val_acc: 0.8300\n",
            "Epoch 12/20\n",
            "7982/7982 [==============================] - 1s 143us/step - loss: 0.1729 - acc: 0.9531 - val_loss: 0.8895 - val_acc: 0.8200\n",
            "Epoch 13/20\n",
            "7982/7982 [==============================] - 1s 145us/step - loss: 0.1569 - acc: 0.9543 - val_loss: 0.8957 - val_acc: 0.8210\n",
            "Epoch 14/20\n",
            "7982/7982 [==============================] - 1s 146us/step - loss: 0.1439 - acc: 0.9563 - val_loss: 0.9209 - val_acc: 0.8240\n",
            "Epoch 15/20\n",
            "7982/7982 [==============================] - 1s 143us/step - loss: 0.1349 - acc: 0.9538 - val_loss: 0.9420 - val_acc: 0.8190\n",
            "Epoch 16/20\n",
            "7982/7982 [==============================] - 1s 140us/step - loss: 0.1273 - acc: 0.9549 - val_loss: 0.9420 - val_acc: 0.8260\n",
            "Epoch 17/20\n",
            "7982/7982 [==============================] - 1s 141us/step - loss: 0.1195 - acc: 0.9572 - val_loss: 0.9608 - val_acc: 0.8220\n",
            "Epoch 18/20\n",
            "7982/7982 [==============================] - 1s 138us/step - loss: 0.1143 - acc: 0.9572 - val_loss: 1.0188 - val_acc: 0.8110\n",
            "Epoch 19/20\n",
            "7982/7982 [==============================] - 1s 142us/step - loss: 0.1112 - acc: 0.9579 - val_loss: 1.0083 - val_acc: 0.8200\n",
            "Epoch 20/20\n",
            "7982/7982 [==============================] - 1s 139us/step - loss: 0.1070 - acc: 0.9570 - val_loss: 1.0319 - val_acc: 0.8190\n",
            "2246/2246 [==============================] - 0s 84us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.1686360833906002, 0.7889581478183437]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cr7HZkLecpXW",
        "colab_type": "code",
        "outputId": "cc11e23c-3bdb-490f-b749-e41b27685013",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "experiment(128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7982 samples, validate on 1000 samples\n",
            "Epoch 1/20\n",
            "7982/7982 [==============================] - 3s 318us/step - loss: 1.6068 - acc: 0.6771 - val_loss: 1.0520 - val_acc: 0.7860\n",
            "Epoch 2/20\n",
            "7982/7982 [==============================] - 2s 279us/step - loss: 0.7403 - acc: 0.8453 - val_loss: 0.8737 - val_acc: 0.8110\n",
            "Epoch 3/20\n",
            "7982/7982 [==============================] - 2s 276us/step - loss: 0.4591 - acc: 0.9039 - val_loss: 0.7944 - val_acc: 0.8250\n",
            "Epoch 4/20\n",
            "7982/7982 [==============================] - 2s 280us/step - loss: 0.3119 - acc: 0.9330 - val_loss: 0.7819 - val_acc: 0.8390\n",
            "Epoch 5/20\n",
            "7982/7982 [==============================] - 2s 304us/step - loss: 0.2382 - acc: 0.9420 - val_loss: 0.8168 - val_acc: 0.8310\n",
            "Epoch 6/20\n",
            "7982/7982 [==============================] - 3s 332us/step - loss: 0.1963 - acc: 0.9499 - val_loss: 0.8445 - val_acc: 0.8230\n",
            "Epoch 7/20\n",
            "7982/7982 [==============================] - 2s 283us/step - loss: 0.1693 - acc: 0.9539 - val_loss: 0.8888 - val_acc: 0.8240\n",
            "Epoch 8/20\n",
            "7982/7982 [==============================] - 2s 279us/step - loss: 0.1565 - acc: 0.9538 - val_loss: 0.9163 - val_acc: 0.8160\n",
            "Epoch 9/20\n",
            "7982/7982 [==============================] - 2s 278us/step - loss: 0.1454 - acc: 0.9549 - val_loss: 0.9689 - val_acc: 0.8090\n",
            "Epoch 10/20\n",
            "7982/7982 [==============================] - 2s 302us/step - loss: 0.1346 - acc: 0.9555 - val_loss: 0.9876 - val_acc: 0.8020\n",
            "Epoch 11/20\n",
            "7982/7982 [==============================] - 2s 303us/step - loss: 0.1330 - acc: 0.9562 - val_loss: 1.0419 - val_acc: 0.8080\n",
            "Epoch 12/20\n",
            "7982/7982 [==============================] - 2s 285us/step - loss: 0.1254 - acc: 0.9575 - val_loss: 1.0490 - val_acc: 0.7930\n",
            "Epoch 13/20\n",
            "7982/7982 [==============================] - 2s 297us/step - loss: 0.1242 - acc: 0.9555 - val_loss: 1.0556 - val_acc: 0.8030\n",
            "Epoch 14/20\n",
            "7982/7982 [==============================] - 2s 310us/step - loss: 0.1188 - acc: 0.9585 - val_loss: 1.0798 - val_acc: 0.8040\n",
            "Epoch 15/20\n",
            "7982/7982 [==============================] - 3s 329us/step - loss: 0.1196 - acc: 0.9568 - val_loss: 1.1619 - val_acc: 0.7950\n",
            "Epoch 16/20\n",
            "7982/7982 [==============================] - 2s 293us/step - loss: 0.1140 - acc: 0.9573 - val_loss: 1.1854 - val_acc: 0.8040\n",
            "Epoch 17/20\n",
            "7982/7982 [==============================] - 2s 278us/step - loss: 0.1123 - acc: 0.9574 - val_loss: 1.1925 - val_acc: 0.8070\n",
            "Epoch 18/20\n",
            "7982/7982 [==============================] - 2s 279us/step - loss: 0.1135 - acc: 0.9567 - val_loss: 1.1816 - val_acc: 0.8010\n",
            "Epoch 19/20\n",
            "7982/7982 [==============================] - 2s 285us/step - loss: 0.1116 - acc: 0.9568 - val_loss: 1.2530 - val_acc: 0.7860\n",
            "Epoch 20/20\n",
            "7982/7982 [==============================] - 2s 276us/step - loss: 0.1123 - acc: 0.9555 - val_loss: 1.2537 - val_acc: 0.7950\n",
            "2246/2246 [==============================] - 0s 139us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.4795476751251084, 0.7724844167408726]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f20EyPJcQ-A",
        "colab_type": "text"
      },
      "source": [
        "We were using two hidden layers. Now try to use a single hidden layer, or three hidden layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qfftY4ZcvPi",
        "colab_type": "code",
        "outputId": "cac86c02-165e-4d78-9e62-7bf9effd7113",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "experiment(hidden=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7982 samples, validate on 1000 samples\n",
            "Epoch 1/20\n",
            "7982/7982 [==============================] - 2s 230us/step - loss: 2.9164 - acc: 0.2387 - val_loss: 2.1149 - val_acc: 0.5760\n",
            "Epoch 2/20\n",
            "7982/7982 [==============================] - 1s 185us/step - loss: 1.7348 - acc: 0.5981 - val_loss: 1.6001 - val_acc: 0.6020\n",
            "Epoch 3/20\n",
            "7982/7982 [==============================] - 1s 183us/step - loss: 1.4195 - acc: 0.6254 - val_loss: 1.5046 - val_acc: 0.6150\n",
            "Epoch 4/20\n",
            "7982/7982 [==============================] - 1s 185us/step - loss: 1.2669 - acc: 0.6507 - val_loss: 1.4416 - val_acc: 0.6490\n",
            "Epoch 5/20\n",
            "7982/7982 [==============================] - 2s 191us/step - loss: 1.1486 - acc: 0.6921 - val_loss: 1.4153 - val_acc: 0.6640\n",
            "Epoch 6/20\n",
            "7982/7982 [==============================] - 1s 186us/step - loss: 1.0458 - acc: 0.7221 - val_loss: 1.3769 - val_acc: 0.6720\n",
            "Epoch 7/20\n",
            "7982/7982 [==============================] - 1s 186us/step - loss: 0.9510 - acc: 0.7407 - val_loss: 1.3756 - val_acc: 0.6770\n",
            "Epoch 8/20\n",
            "7982/7982 [==============================] - 1s 183us/step - loss: 0.8763 - acc: 0.7518 - val_loss: 1.3734 - val_acc: 0.6870\n",
            "Epoch 9/20\n",
            "7982/7982 [==============================] - 1s 184us/step - loss: 0.8098 - acc: 0.7620 - val_loss: 1.3501 - val_acc: 0.6930\n",
            "Epoch 10/20\n",
            "7982/7982 [==============================] - 1s 184us/step - loss: 0.7495 - acc: 0.7726 - val_loss: 1.3910 - val_acc: 0.7010\n",
            "Epoch 11/20\n",
            "7982/7982 [==============================] - 1s 186us/step - loss: 0.6952 - acc: 0.7977 - val_loss: 1.3782 - val_acc: 0.7000\n",
            "Epoch 12/20\n",
            "7982/7982 [==============================] - 2s 189us/step - loss: 0.6460 - acc: 0.8208 - val_loss: 1.4136 - val_acc: 0.7080\n",
            "Epoch 13/20\n",
            "7982/7982 [==============================] - 1s 184us/step - loss: 0.5996 - acc: 0.8375 - val_loss: 1.4386 - val_acc: 0.7100\n",
            "Epoch 14/20\n",
            "7982/7982 [==============================] - 1s 188us/step - loss: 0.5611 - acc: 0.8507 - val_loss: 1.4714 - val_acc: 0.7070\n",
            "Epoch 15/20\n",
            "7982/7982 [==============================] - 1s 184us/step - loss: 0.5272 - acc: 0.8619 - val_loss: 1.4634 - val_acc: 0.7170\n",
            "Epoch 16/20\n",
            "7982/7982 [==============================] - 1s 183us/step - loss: 0.4997 - acc: 0.8688 - val_loss: 1.4891 - val_acc: 0.7170\n",
            "Epoch 17/20\n",
            "7982/7982 [==============================] - 1s 183us/step - loss: 0.4747 - acc: 0.8733 - val_loss: 1.5671 - val_acc: 0.7090\n",
            "Epoch 18/20\n",
            "7982/7982 [==============================] - 1s 183us/step - loss: 0.4541 - acc: 0.8751 - val_loss: 1.6016 - val_acc: 0.7080\n",
            "Epoch 19/20\n",
            "7982/7982 [==============================] - 1s 186us/step - loss: 0.4344 - acc: 0.8765 - val_loss: 1.6318 - val_acc: 0.7110\n",
            "Epoch 20/20\n",
            "7982/7982 [==============================] - 1s 182us/step - loss: 0.4176 - acc: 0.8802 - val_loss: 1.6652 - val_acc: 0.7070\n",
            "2246/2246 [==============================] - 0s 101us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.8030590057797657, 0.6954585931073951]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gerhBElScwvh",
        "colab_type": "code",
        "outputId": "ac718a24-ce4f-4772-fb5e-cbfae457f764",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "experiment(hidden=3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7982 samples, validate on 1000 samples\n",
            "Epoch 1/20\n",
            "7982/7982 [==============================] - 2s 235us/step - loss: 2.6873 - acc: 0.3730 - val_loss: 1.8103 - val_acc: 0.5830\n",
            "Epoch 2/20\n",
            "7982/7982 [==============================] - 1s 185us/step - loss: 1.5977 - acc: 0.6006 - val_loss: 1.5034 - val_acc: 0.6150\n",
            "Epoch 3/20\n",
            "7982/7982 [==============================] - 1s 182us/step - loss: 1.3288 - acc: 0.6432 - val_loss: 1.4104 - val_acc: 0.6320\n",
            "Epoch 4/20\n",
            "7982/7982 [==============================] - 1s 182us/step - loss: 1.1373 - acc: 0.7082 - val_loss: 1.3018 - val_acc: 0.6940\n",
            "Epoch 5/20\n",
            "7982/7982 [==============================] - 1s 184us/step - loss: 0.9981 - acc: 0.7523 - val_loss: 1.2705 - val_acc: 0.7070\n",
            "Epoch 6/20\n",
            "7982/7982 [==============================] - 1s 182us/step - loss: 0.8903 - acc: 0.7747 - val_loss: 1.2764 - val_acc: 0.7150\n",
            "Epoch 7/20\n",
            "7982/7982 [==============================] - 1s 182us/step - loss: 0.8024 - acc: 0.7953 - val_loss: 1.2672 - val_acc: 0.7180\n",
            "Epoch 8/20\n",
            "7982/7982 [==============================] - 2s 213us/step - loss: 0.7304 - acc: 0.8109 - val_loss: 1.3047 - val_acc: 0.7220\n",
            "Epoch 9/20\n",
            "7982/7982 [==============================] - 1s 187us/step - loss: 0.6663 - acc: 0.8231 - val_loss: 1.3315 - val_acc: 0.7150\n",
            "Epoch 10/20\n",
            "7982/7982 [==============================] - 2s 211us/step - loss: 0.6132 - acc: 0.8326 - val_loss: 1.3752 - val_acc: 0.7210\n",
            "Epoch 11/20\n",
            "7982/7982 [==============================] - 1s 187us/step - loss: 0.5655 - acc: 0.8514 - val_loss: 1.4317 - val_acc: 0.7160\n",
            "Epoch 12/20\n",
            "7982/7982 [==============================] - 1s 181us/step - loss: 0.5240 - acc: 0.8636 - val_loss: 1.4347 - val_acc: 0.7220\n",
            "Epoch 13/20\n",
            "7982/7982 [==============================] - 1s 181us/step - loss: 0.4891 - acc: 0.8740 - val_loss: 1.4629 - val_acc: 0.7350\n",
            "Epoch 14/20\n",
            "7982/7982 [==============================] - 1s 178us/step - loss: 0.4558 - acc: 0.8836 - val_loss: 1.5207 - val_acc: 0.7230\n",
            "Epoch 15/20\n",
            "7982/7982 [==============================] - 1s 180us/step - loss: 0.4297 - acc: 0.8913 - val_loss: 1.5654 - val_acc: 0.7190\n",
            "Epoch 16/20\n",
            "7982/7982 [==============================] - 1s 181us/step - loss: 0.4069 - acc: 0.9000 - val_loss: 1.5753 - val_acc: 0.7290\n",
            "Epoch 17/20\n",
            "7982/7982 [==============================] - 1s 187us/step - loss: 0.3840 - acc: 0.9049 - val_loss: 1.6551 - val_acc: 0.7120\n",
            "Epoch 18/20\n",
            "7982/7982 [==============================] - 1s 180us/step - loss: 0.3678 - acc: 0.9069 - val_loss: 1.6580 - val_acc: 0.7130\n",
            "Epoch 19/20\n",
            "7982/7982 [==============================] - 2s 232us/step - loss: 0.3499 - acc: 0.9134 - val_loss: 1.7799 - val_acc: 0.6980\n",
            "Epoch 20/20\n",
            "7982/7982 [==============================] - 2s 192us/step - loss: 0.3353 - acc: 0.9148 - val_loss: 1.7416 - val_acc: 0.7020\n",
            "2246/2246 [==============================] - 0s 104us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.132171247011832, 0.6763134461795233]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    }
  ]
}